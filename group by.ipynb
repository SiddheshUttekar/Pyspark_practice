{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31cd0063-eda6-4260-82e0-472e52a52b66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92f1e990-d5e9-45ee-a5ee-6dc7d8999b5a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_data = [\n",
    "    (1, 'manish', 50000, 'IT'),\n",
    "    (2, 'vikash', 60000, 'sales'),\n",
    "    (3, 'raushan', 70000, 'marketing'),\n",
    "    (4, 'mukesh', 80000, 'IT'),\n",
    "    (5, 'pritam', 90000, 'sales'),\n",
    "    (6, 'nikita', 45000, 'marketing'),\n",
    "    (7, 'ragini', 55000, 'marketing'),\n",
    "    (8, 'rakesh', 100000, 'IT'),\n",
    "    (9, 'aditya', 65000, 'IT'),\n",
    "    (10, 'rahul', 50000, 'marketing')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91a9587b-5487-459d-a2b1-8c89d269903c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_schema=['id','name','salary','dept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab3f1244-5460-4220-9e35-f5e23f28ebb0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_df=spark.createDataFrame(data=emp_data,schema=emp_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0038daf0-264e-432e-9cb1-1f0f223bf77d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+---------+\n| id|   name|salary|     dept|\n+---+-------+------+---------+\n|  1| manish| 50000|       IT|\n|  2| vikash| 60000|    sales|\n|  3|raushan| 70000|marketing|\n|  4| mukesh| 80000|       IT|\n|  5| pritam| 90000|    sales|\n|  6| nikita| 45000|marketing|\n|  7| ragini| 55000|marketing|\n|  8| rakesh|100000|       IT|\n|  9| aditya| 65000|       IT|\n| 10|  rahul| 50000|marketing|\n+---+-------+------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "785c914c-38cf-4303-bcc4-c00aeab1654d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "what is the total salary given to its employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42e48d48-b283-44d2-bba5-72881cec9edf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n|sum(salary)|\n+-----------+\n|     665000|\n+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_df.select(sum(\"salary\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a92f0e9-4641-4c6e-8b33-76d9b532068c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "what is the total salary per department wise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1cf73d0-d988-4103-9f8d-13eecd5ae93e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n|     dept|sum(salary)|\n+---------+-----------+\n|       IT|     295000|\n|    sales|     150000|\n|marketing|     220000|\n+---------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_df.groupBy(\"dept\")\\\n",
    "     .agg(sum(\"salary\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0acf803a-5427-415b-a916-82f93a25fb1b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "i want all columns name with one extra column where total salary of each dept is mentioned\n",
    "\n",
    "or\n",
    "\n",
    "i want % age of salary given to each employee per department wise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f777a9f0-2293-41eb-85d0-56f380983e60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_data2 = [\n",
    "    (1, 'manish', 50000, 'IT', 'india'),\n",
    "    (2, 'vikash', 60000, 'sales', 'us'),\n",
    "    (3, 'raushan', 70000, 'marketing', 'india'),\n",
    "    (4, 'mukesh', 80000, 'IT', 'us'),\n",
    "    (5, 'pritam', 90000, 'sales', 'india'),\n",
    "    (6, 'nikita', 45000, 'marketing', 'us'),\n",
    "    (7, 'ragini', 55000, 'marketing', 'india'),\n",
    "    (8, 'rakesh', 100000, 'IT', 'us'),\n",
    "    (9, 'aditya', 65000, 'IT', 'india'),\n",
    "    (10, 'rahul', 50000, 'marketing', 'us')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca74b057-5e9f-401f-b69b-e20b75334f6e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_schema2=['id','name','salary','dept','country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7947e127-98bc-471e-877c-112560a8a5bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_df2=spark.createDataFrame(data=emp_data2,schema=emp_schema2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "639c194f-6ed4-45ab-a4fa-71ea0b2fcd9b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+---------+-------+\n| id|   name|salary|     dept|country|\n+---+-------+------+---------+-------+\n|  1| manish| 50000|       IT|  india|\n|  2| vikash| 60000|    sales|     us|\n|  3|raushan| 70000|marketing|  india|\n|  4| mukesh| 80000|       IT|     us|\n|  5| pritam| 90000|    sales|  india|\n|  6| nikita| 45000|marketing|     us|\n|  7| ragini| 55000|marketing|  india|\n|  8| rakesh|100000|       IT|     us|\n|  9| aditya| 65000|       IT|  india|\n| 10|  rahul| 50000|marketing|     us|\n+---+-------+------+---------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ac8cab1-a5ac-4fb0-b3ff-84ccf1cf5d34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-----------+\n|     dept|country|sum(salary)|\n+---------+-------+-----------+\n|       IT|  india|     115000|\n|    sales|     us|      60000|\n|marketing|  india|     125000|\n|    sales|  india|      90000|\n|       IT|     us|     180000|\n|marketing|     us|      95000|\n+---------+-------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_df2.groupBy(\"dept\",\"country\")\\\n",
    "    .agg(sum(\"salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86c5369b-14fa-446b-be04-d1e6bd177c4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select dept, sum(\"salary\")\n",
    "          from table\n",
    "          group by dept\n",
    "          \"\"\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "group by",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
